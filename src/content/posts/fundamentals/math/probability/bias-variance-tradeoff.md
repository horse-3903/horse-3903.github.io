---
title: Bias-Variance Tradeoff
published: 2026-02-16
description: "Math fundamentals note for IOAI ML preparation."
tags: ["Mathematics Fundamentals", "Probability"]
category: IOAI ML Notes
draft: false
access: public
---
# Syllabus Map

* Study map: [Syllabus Study Map](/posts/syllabus/ioai-study-map/)

---

# Core Idea

* Total error can be decomposed into bias, variance, and irreducible noise.

## Practical Notes

### High bias underfits; high variance overfits.

* Model complexity and regularization control this tradeoff.

## Why This Matters for ML

* The bias-variance framework explains why models underfit or overfit.
* Regularization, ensembling, and model capacity decisions are guided by this tradeoff.
* It provides a principled lens for interpreting validation curves and generalization gaps.
* Many syllabus topics (bagging, boosting, ridge/lasso) are direct bias-variance interventions.